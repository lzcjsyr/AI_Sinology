# 中文系论文撰写流程与 AI 智能体辅助方案

## 1. 系统架构与运行说明 (System Architecture & Operations)

- **交互方式**：本系统为一个基于命令行界面 (CLI) 进行交互的自动化控制程序，旨在为专业研究者提供高效率、无干扰的调度体验。
- **存储机制**：所有的工作产物及阶段性文件，统一存储在根目录下的 `outputs` 文件夹中。系统以“一个研究项目为一个子文件夹”的形式进行隔离和管理（例如：`outputs/late_ming_merchants/`）。
- **流程规范**：为确保多轮多层级级联生成的文件顺序清晰，每一个步骤生成的输出文件，其文件名前均自动挂载了对应的阶段序号（如第一阶段生成的文件以 `1_` 开头，第二阶段为 `2_` 等）。
- **LLM 调度框架**：针对底层的结构化输出约束、多模型切换调优及 Prompt 编排，本系统全面采用 [DSPy](https://dspy-docs.vercel.app/) 包进行声明式编程与集中管理。

## 2. 核心流程与 Agent 赋能协作 (Core Workflow & Agent Collaboration)

中文系（及相关人文学科）的论文撰写通常遵循严谨的学术规范。单一的大模型（LLM）难以独立完成长篇论文，但一组分工明确的多智能体系统 (Multi-Agent System) 可以深度嵌入传统流程，进行高效协作。以下是五个核心阶段的传统做法及其对应的智能体辅助方案。

### 第一阶段：选题与构思 (Topic Selection & Conception)

#### 1. 流程介绍

- **发现问题**：通过阅读经典文本（如《诗经》、《红楼梦》等）或二手研究，发现未被充分探讨的问题。
- **文献回顾**：检索知网 (CNKI)、JSTOR、万方等数据库，梳理前人研究成果，确立前沿边界并寻找研究空白。
- **确定选题**：从小切口入手，确立兼具学术价值与可行性的具体题目。

#### 2. Agent 介绍：选题顾问智能体 (Topic Advisor Agent)

- **设计思路**：对接入海量学术文献库，利用数据驱动的方法发现学术热点和空白。
- **功能定位**：分析跨语种检索前沿文献，并为人类研究者提供具体的、具有可行性的选题方向建议。
- **数据源**：对接 [Semantic Scholar API](https://www.semanticscholar.org/product/api/tutorial) 等获取权威学术数据（通过 MCP 服务器封装接口）。
- **人机交互示例**：
  - **人类输入**：“我想研究晚明通俗小说中的商人形象。”
  - **Agent 输出**：生成 5 个具体的选题方向，并列出相关的 10 篇核心文献。

#### 3. 输入

- **信息来源**：人类最初的、可能较模糊的研究意向、关键词或特定的经典文本段落。
- **具体示例**：“我想研究晚明通俗小说中的商人形象”、“近年来关于《红楼梦》后四十回作者争议的新材料”。

#### 4. 输出

*本阶段目标对标**博士生开题标准**，总计约 **8,000 字**。因总字数庞大且逻辑严密性要求极高，**必须采用“多轮串行（非并行）”策略调用 LLM**。后续每一部分的生成，都必须将前面已生成的所有内容作为上下文输入（Context），以确保全文逻辑高度连贯与自洽。*

- **输出文件**：**1 个文件**（《研究计划书 / 开题报告》(Research Proposal)，如存为 `1_research_proposal.md`）。
- **数据结构与格式要求**：Markdown 或富文本格式，包含 6 个按顺序串行生成的结构化文本块。
  1. **[第一轮生成] 研究背景与问题陈述 (Problem Statement) —— 约 1,000 字**
     - 清晰界定你要解决的核心现象或学术争论，奠定全篇语境与研究的合法性。
  2. **[第二轮生成，基于第一轮结果] 核心研究问题 (Research Questions) —— 约 500 字**
     - 基于第一步的背景，沿流溯源提出 3-5 个具体、具有内在逻辑递进深度的研究主干问题及子问题。
  3. **[第三轮生成，基于前两轮结果] 学术史述评 (Literature Review) —— 约 3,500 字**
     - **（核心重头戏）**紧扣上文的“核心问题”，按主题或流派对前人研究成果进行详尽梳理。必须进行**批判性评价**，明确指出当前研究的僵局、不足或空白。
  4. **[第四轮生成，基于前三轮结果] 研究思路与切入点 (Methodology & Perspective) —— 约 1,000 字**
     - 针对第三步指出的“空白”，详细规划本研究的突破口：采用何种理论工具、引用的核心原始文献处理方法或跨学科视角。需附带初步的章节大纲。
  5. **[第五轮生成，基于前四轮结果] 预期创新与学术价值 (Significance & Innovation) —— 约 1,000 字**
     - 综合前四部的推演结论，升华立意，论证本研究在理论建构或新史料发掘上能为该领域贡献什么不可替代的新知。
  6. **[第六轮生成，基于前五轮结果] 史料检索策略与阅读提示词 (Archival Search Strategy & LLM Prompts) —— 约 500 字**
     - **目标主题列表**：输出一个或多个并行的检索目标主题。格式需统一为“几个字的主题核心词：一到几句话的具体解释（含筛选标准）”。例如：“祈雨：包括皇帝和民间百姓通过宗教活动和民间习俗请求降雨，以帮助农耕生产的情况；史料须包含具体数字、时间或明确的祈雨仪式过程，排除空泛的道德议论”。基于上述解释，列出各类主题在古语中可能有的同义词/关联词（如搜“商人”兼查“商贾”、“牙人”）。
     - **靶向清单**：基于经验列出最可能包含该类史料的基础文献目录（如特定方志、传教士日记、档案汇编等），划定核心检索范围。

---

### 第二阶段：史料搜集与多模型交叉验证整理 (Data Collection & Cross-Validation)

*注：这是中文系研究最关键、工作量最大的环节。*

#### 1. 流程介绍

- **文本细读**：深入研读原始文献（Primary Sources），如史书、集部、笔记小说等，做到“无一字无来历”。
- **考据与校勘**：确认文本的版本差异、字义解释，辨伪存真。
- **建立文献库**：摘录关键引文，分类整理论据，撰写初步的按语或札记。

#### 2. Agent 介绍：多模型并发史料挖掘智能体 (Multi-LLM Archival Digger Agent)

- **设计思路**：利用 LLM 极快的阅读和信息提取能力，替代人类进行枯燥的海量文本初筛。引入多模型交叉验证（Cross-Validation）机制，规避单一模型的幻觉和遗漏，确保所摘取史料的绝对可靠性。
- **功能定位**：
  - 针对选定的目标基础文献进行**穷举式阅读**。将长文本拆分为小片段（每次阅读一小部分），交由大模型进行判断。
  - **双模型并发初筛**：同时调用 2 个不同的 LLM 分别独立进行打分，互不干扰。每个 LLM 都要能进行并发处理，以最大幅度加快检索和阅读速度。
  - **第三方仲裁核验**：调用第 3 个独立的 LLM，针对初筛中产生争议的材料片段进行重新阅读和核验裁断。

#### 3. 输入

- **信息来源**：
  1. 【第一阶段】输出文件中的“第 6 项”：包含具体释义及筛选标准的**“目标主题列表”**（作为本阶段进行自动化分类和打分的基准 System Prompt）。
  2. 预先准备好的、被切分为小文本片段的**原始史料文献库**（TXT 或 JSON 格式的古代典籍片段）。

#### 4. 输出

*本阶段经过完整的并发阅读、代码自动比对与第三方校验，必须且将输出以下 **6 个文档集合**（并保存在本地）。*

- **输出文件列表**：
  - `2_llm1_raw.jsonl`: 第 1 个 LLM 对所有片段独立打分与阅读的原始文档。
  - `2_llm2_raw.jsonl`: 第 2 个 LLM 对所有片段独立打分与阅读的原始文档。
  - `2_consensus_data.yaml`: 调用脚本对比文档 1 和 2，将判定完全相同（判定毫无分歧）的部分单独摘出生成的绝佳素材档案。
  - `2_disputed_data.yaml`: 调用脚本对比文档 1 和 2，将判定有出入（如一是一否，或高低分档不同）的材料摘取生成的待核准档案。
  - `2_llm3_verified.yaml`: 第三方 LLM 针对 `2_disputed_data.yaml`（分歧材料集）进行重新仲裁判读后的结果文档。
  - `2_final_corpus.yaml`: **最终核心产出**。拼接合并无争议的 `2_consensus_data.yaml` 和经过评评判后的 `2_llm3_verified.yaml`，形成向下一阶段流转的高价值史料总库。
- **数据结构与格式要求**：采用**双轨格式策略**。底层并发生成的原始档案统一使用抗穿插能力极强的 **JSONL**（每行一项），而供人阅读核验的文件（特别是 `final_corpus.yaml`）则自动转存为人类极度友好的 **YAML** 格式。每次阅读分析的片段必须严格遵守以下 6 个结构字段：
  - **非 LLM 生成（由代码注入的元数据 MetaData）**：
    1. `piece_id`: 片段序号或唯一标示（如 "001"）。
    2. `source_file`: 史料出处（如《醒世恒言》卷一）。
    3. `original_text`: 截取喂给 LLM 的史料原文（YAML 转存时使用 `|` 语法支持多行文本）。
  - **由 LLM 严守生成的分析结果 (AI Generated Data)**：
    4. `matched_theme`: 明确标明该片段是根据第一阶段列出的哪一个具体“目标主题”（如“祈雨”）筛选出来的相关信息。
    5. `is_relevant`: 仅能作答“是”或“否”。
    6. `reason`: 详细说明该片段为什么和该匹配主题相关，以及后续评定相关度档次的依据（YAML 同样使用 `|` 保存长片段）。
    7. `relevance_level`: “高”、“中”、“低”三档；不相关则为空。

---

### 第三阶段：大纲构建与逻辑推演 (Outlining)

#### 1. 流程介绍

- **谋篇布局**：设计科学严密的章节结构（绪论、本论、结论），确保各章体量均衡。
- **逻辑论证**：确立每一章的核心论点（Sub-arguments）及其支撑总论点（Thesis Statement）的逻辑关系。

#### 2. Agent 介绍：大纲架构智能体 (Architect Agent)

- **设计思路**：模仿人类导师的审视视角，在正式动笔前，对史料和意图进行沙盘推演。
- **功能定位**：基于一、二阶段确立的选题和汇编好的高质量史料，自动推演并生成多级论文大纲。其核心价值在于审查逻辑链条的完整性，如“第三章提供的史料是否足以支撑总论点？”、“各章节之间是否存在逻辑断层或重复？”。它会主动指出漏洞，并建议人类补充缺失维度的史料。

#### 3. 输入

- **信息来源**：
  1. 【第一阶段】产出的**《研究计划书》**（提供宏观论点和研究目的）。
  2. 【第二阶段】终产出的 **`2_final_corpus.yaml`** (提供具体的微观史料支撑体系)。

#### 4. 输出

*论文的骨架建筑图，决定了全文的起承转合是否严密。*

- **输出文件**：**1 个文件**（《三级论纲与逻辑推演表》(Detailed Three-level Outline & Logical Matrix)，如存为 `3_outline_matrix.md`）。
- **数据结构与格式要求**：层级嵌套的结构化文档（通常为 Markdown 或 JSON），必须包含但不限于以下五个层级的逻辑骨架：
  1. **核心论点 (Thesis Statement)**：用**一句极其凝练的话**概括全篇的核心结论与主旨。
  2. **第一级标题（章纲）：核心分论点 (Chapter Arguments)**：每一章的主题及其在论证长链中的位置（递进、并列或转折）。
  3. **第二级标题（节纲）：逻辑支撑与过渡 (Section Transitions)**：具体展开论证的逻辑台阶。
  4. **第三级标题（目纲）：核心史料锚点 (Evidence Anchors)**：明确这一段落将使用前一阶段挖掘的哪些具体“史料卡片”（**精准映射到 `2_final_corpus.yaml` 中的 `piece_id` 锚点**）来佐证。
  5. **潜在反驳与回应策略 (Counter-arguments & Rebuttals)**：预判可能的学术质疑（如存在相反解释的史料），并设下回应或补救方案。

---

### 第四阶段：撰写初稿 (Drafting)

#### 1. 流程介绍

- **引经据典**：将史料证据融入论述中，严格遵守“无征不信”、“孤证不立”的史学原则。
- **文本阐释**：对引文进行细致的学术破译、阐释与升华，避免“以论代史”或单纯的“史料堆砌”。

#### 2. Agent 介绍：写作执行智能体 (Writer Agent)

- **设计思路**：将长篇大论的写作任务，拆解为数十个基于可靠卡片（史料）的“微型读书笔记”，再无缝拼接。
- **功能定位**：遵循“大纲架构智能体”规划的路径，逐章、逐节撰写初稿。**关键限制**：必须严格限制为“检索增强生成 (RAG)”模式。即强制 Agent 基于“史料挖掘智能体”提供的史料卡片进行“读后感式”的破译与阐释计算，严禁 LLM 发挥其参数内含的“幻觉”去编造或修改古籍引文。

#### 3. 输入

- **信息来源**：
  1. 【第三阶段】产出的**《三级论纲》**（提供结构和走向）。
  2. 【第二阶段】终产出的 **`2_final_corpus.yaml`** 中被大纲所锚定的特定史料卡片块。
  3. **人类指令**（可选）：细分到某一个章节或子节的微调指令。例如：“请基于提供的 5 条《醒世恒言》引文卡片，论证总结明代商人的契约讲信观念，800字左右。”

#### 4. 输出

*实现从“材料汇编”到“系统论述文本”的转化，注重血肉丰满与史论结合。*

- **输出文件**：**1 个文件**（《论文初稿》(First Draft)，如存为 `4_first_draft.md`）。
- **数据结构与格式要求**：标准的学术长文本格式（Markdown / Word），须清晰呈现以下 4 大板块的线性结构：
  1. **绪论 (Introduction)**：引出核心提问，精彩呈现学术史述评，抛出中心论点与研究意义（由开题报告扩充升华而来）。
  2. **本论部分 (Body Paragraphs)**：
     - 以“主题句 (Topic Sentence)”引领每一个段落逻辑。
     - **微观推演模式**必须固定为：提出小观点 -> 呈现权威史料（一字不增删） -> 对史料文字进行精密切割、阐释与分析 -> 段落小结与收束。
  3. **结论 (Conclusion)**：超越简单的文意重复，升华研究结论，并客观指出本研究的局限性及未来可拓展的空间。
  4. **初排版的引注区 (Draft Citations)**：文内暂存的引文来源注释。

---

### 第五阶段：修改与润色 (Revision & Polishing)

#### 1. 流程介绍

- **学术规范复核**：严格核对注释格式（如《历史研究》体例、GB/T 7714、MLA或Chicago），确保引证绝对准确。
- **语言打磨**：确保用词雅正、学术词汇使用精确、句式长短错落，剔除冗余修辞与随意口语化表达。

#### 2. Agent 介绍：审稿与校对智能体 (Reviewer Agent)

- **设计思路**：充当毫无感情色彩的“格式纠偏器”与“语体转换器”。
- **功能定位**：自动执行学术规范的最后一道门槛检查。它将执行：
  1. **引文查纠**：交叉比对引文内容与原始文献库，检测是否有断章取义或轻微的文字错漏。
  2. **学术语体转换**：将初稿中过于直白、口语化或是过度翻译腔的句子，润色为符合特定学科（如古典文献学）审美的雅正学理语言。
  3. **自动化格式排版**：一键将所有零散的内文注释，转化为统一的脚注或尾注（如 BibTeX 或特定国标），生成无可挑剔的参考文献表。

#### 3. 输入

- **信息来源**：
  1. 【第四阶段】的**《论文初稿》**全文。
  2. 包含原文和出处的**原始史料库**（用于二次核查核对原文本形貌）。
  3. 目标期刊或学位论文的**具体格式规范文件**（例如：“请遵循北京大学博士论文写作体例要求”）。

#### 4. 输出

*达到可发表或学位答辩标准的最终学术成品。*

- **输出文件**：逻辑上算作 **1 个完整打包件**（包含 1 个“主文档”与 1 个“日志记录文档”）。
- **数据结构与格式要求**：排版精良的交钥匙解决方案：
  1. **主文档 (`5_final_manuscript.docx`)**:
     - **标准化中英文摘要与关键词 (Standardized Abstract & Keywords)**：高度浓缩论文精华。
     - **规范达标的整篇定稿 (Polished Exact Manuscript)**：语言洗练，逻辑无懈可击。所有的注释标记与脚注编号绝对对应。
     - **体例统一的参考文献表 (Standardized Bibliography)**：无一遗漏、自动按首字母或笔画排版的参考文献清单。
  2. **日志随附文档 (`5_revision_checklist.md`) 自检清单**:
     - 逻辑修改溯源与盲点排查记录。
     - 引文原始出处二次抽检的复核日志（标明：“已比对 135 条引文，文字 100% 准确”）。
     - 查重与学术规范格式匹配的自测报告

## 3. 程序代码文件结构与步骤划分 (Program File Structure & Step Division)

为了保证整个流程的功能和边界清晰易懂，本系统不仅将其解耦为 **6个独立且前后衔接的业务执行步骤**，还根据软件工程的最佳实践（DRY原则），抽离了全局共享的核心模块（如日志、多模型路由配置）。各业务模块只需专注于特定逻辑，通过读取上一阶段输出的文件驱动，并将本阶段结果写入 `outputs/项目名/` 目录下。

值得强调的是，为了最大化发挥各大厂商（如 OpenAI, 智谱, DeepSeek, 硅基流动等）的能力及其并发优势，**系统的每一个单一步骤都可以配置使用不同的服务商和模型**。

### 核心代码文件结构设计

```text
thesis_agent_system/
├── main.py                          # 全局调度入口：可通过命令行参数单独运行某一步骤或串联全流程
├── .env                             # 环境变量配置文件：存放各家厂商的 API Key 及核心全局参数
├── .env.example                     # 环境变量示例文件：供新部署者填入自己的 Key
├── core/                            # 核心公共组件 (Shared Modules)
│   ├── config.py                    # 全局配置管理：读取 .env、加载各步骤的模型路由表与提示词路径
│   ├── logger.py                    # 统一日志模块：定义终端高亮输出与持久化日志文件 (如 app.log)
│   ├── llm_client.py                # LLM 多模型调度封装：底层利用 LiteLLM 统一封装不同产商的 API 格式，处理并发限流与熔断，上层对接 DSPy
│   └── utils.py                     # 通用工具箱：文件读写(Markdown/YAML解析)、数据结构清洗、格式校验
├── workflow/                        # 核心业务流程 (Core Workflow Steps)
│   ├── topic_selection.py           # 步骤1：选题顾问与构思 (对应第一阶段)
│   ├── stage2_data_collection/      # ★ 史料搜集与并发清洗阶段 (对应第二阶段)
│   │   ├── data_ingestion/          # 异构数据标准化接入层 (针对各类数据源独立脚本)
│   │   │   ├── parse_kanripo.py     # Kanripo 格式数据抽取与切片
│   │   │   └── parse_cbdb.py        # CBDB 数据解析提取
│   │   ├── archival_screening.py    # 步骤2：双模型并发初筛 (基于统一片段池)
│   │   └── archival_arbitration.py  # 步骤3：争议仲裁与核心史料汇编
│   ├── outlining.py                 # 步骤4：大纲构建与逻辑推演 (对应第三阶段)
│   ├── drafting.py                  # 步骤5：RAG增强撰写初稿 (对应第四阶段)
│   └── polishing.py                 # 步骤6：审稿、校验与格式定稿 (对应第五阶段)
├── prompts/                         # 提示词库：将 Prompt 与 Python 代码剥离，统一存放于 YAML 模板
├── outputs/                         # 统一的数据与产物输出目录
│   └── example_project/             # (存放所有 1_*, 2_*, 3_* 等流水线文件)
└── data/                            # 原材料存量目录
    ├── kanripo_repos/               # 存放未经处理的各类原始语料 (Kanripo txt 等)
    └── processed/                   # 经过 data_ingestion/ 清洗后，统一输出的标准 JSONL 史料片段池
```

### 各独立文件功能与边界界定

#### 步骤 1：`topic_selection.py` (选题顾问)

- **功能边界**：仅处理方向确立、文献检索与研究计划书的生成。
- **主要输入**：人类最初始的模糊想法或特定提示词。
- **核心逻辑**：调用公共 `llm_client.py` 并组装 `prompts/` 下的指令，串行生成《研究计划书》。此阶段建议配置擅长宏观推理的高智商模型 (如 GPT-4o 或 GLM-4)。
- **主要输出**：`1_research_proposal.md` 及包含严格筛选标准的“目标检索主题列表”。

#### 【第二阶段专属】`stage2_data_collection/data_ingestion/*` (异构数据接入)

- **功能边界**：作为步骤2的前置准备，将来源复杂、格式各异（TXT、XML、数据库等分类存放在 `data/kanripo_repos/` 等类似目录下的原始史料）清洗并拆分为统一尺寸的独立片段。
- **核心逻辑**：各个专用脚本（如 `parse_kanripo.py`）负责将其对应数据源的元信息（如卷、页）提取清洗，确保片段长度均等并附带溯源 ID (`piece_id`)。
- **主要输出**：输出到 `data/processed/` 的统一格式 JSONL 文件池，供后续步骤并发读取。

#### 步骤 2：`stage2_data_collection/archival_screening.py` (史料并发初筛)

- **功能边界**：负责海量文本的异步阅读和双重并发打分，但不涉及最终分歧的结论判断。
- **主要输入**：步骤1指定的主题列表，以及由 `data_ingestion/` 产出的 `data/processed/` 标准史料片段池。
- **核心逻辑**：最考验系统吞吐率的一步。利用 `core/config.py` 配置多个并发模型矩阵（比如同时派送任务给 DeepSeek-V3 接口矩阵和 GLM-4 接口矩阵），利用底层大模型的并发池实现无损打分（相关性、评级、理由）。即使单条 API 触发限流，底层也会自动轮询下一个。
- **主要输出**：原始记录 `2_llm1_raw.jsonl` / `2_llm2_raw.jsonl`，以及初分流文件 `2_consensus_data.yaml` (共识记录) 和 `2_disputed_data.yaml` (争议记录)。

#### 步骤 3：`stage2_data_collection/archival_arbitration.py` (争议仲裁与汇编)

- **功能边界**：解决并发打分中的判断分歧，最终定稿本研究可用且高可靠的“核心史料库”。
- **主要输入**：步骤2生成的 `2_disputed_data.yaml` 和 `2_consensus_data.yaml`。
- **核心逻辑**：调用配置好的极其严谨的第三方权威大模型 (如 Claude-3.5-Sonnet) 针对争议文档重新核定，利用 `utils.py` 合并结构化数据。
- **主要输出**：`2_llm3_verified.yaml` (仲裁记录) 及核心精炼资料 `2_final_corpus.yaml`。

#### 步骤 4：`outlining.py` (大纲架构)

- **功能边界**：仅负责逻辑编排和论证骨架搭建，决不生成具体的连贯行文。
- **主要输入**：宏观《研究计划书》+ 微观史料库 `2_final_corpus.yaml`。
- **核心逻辑**：沙盘推演生成三级逻辑大纲，并将章节的底层论据严格映射至特定的片段 ID。
- **主要输出**：`3_outline_matrix.md`（三级论纲与史料映射逻辑推演表）。

#### 步骤 5：`drafting.py` (撰写初稿)

- **功能边界**：严格遵循 RAG 原则：只基于给定史料卡片写作，杜绝幻觉编造史料。
- **主要输入**：步骤4产生的三级大纲 + 绑定的古籍片段材料。
- **核心逻辑**：逐章按纲撰写，基于底层 `llm_client.py` 严格输入限制，完成学术阐释和行文无缝拼接。
- **主要输出**：`4_first_draft.md`（未深度打磨格式但论述连贯的具体初稿全文+初排引用标注）。

#### 步骤 6：`polishing.py` (审稿与校对)

- **功能边界**：全流程最后的拦截器，不对初稿进行破坏性重组，专注遣词造句与核心校验。
- **主要输入**：步骤5生成的初稿 `4_first_draft.md`、原始史料库、目标排版要求。
- **核心逻辑**：通过自动化脚本核验证引文字符一致性（抗漏诊）；润色为传统人文学术体、生成并按规范挂载脚注。
- **主要输出**：符合学术规范、经过严格排版优化的定点格式版 `5_final_manuscript.docx`，及自检日志 `5_revision_checklist.md`。
